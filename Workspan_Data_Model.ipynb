{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Storage and Access Patterns (including Astra Vector Search)\n",
        "\n"
      ],
      "metadata": {
        "id": "-neIomNS4cl6"
      },
      "id": "-neIomNS4cl6"
    },
    {
      "cell_type": "markdown",
      "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e",
      "metadata": {
        "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e"
      },
      "source": [
        "# Table Schema\n",
        "\n",
        "```\n",
        "CREATE TABLE IF NOT EXISTS workspan.customer_opportunities (\n",
        "    customer_id text,\n",
        "    partner_id text,\n",
        "    opportunity_id text,\n",
        "    customer_name text static,\n",
        "    llm_output text,\n",
        "    opportunity map<text, text>,\n",
        "    llm_output_embedding vector<float, 1536>,\n",
        "    sentiment text,\n",
        "    PRIMARY KEY ((customer_id, partner_id), opportunity_id)\n",
        ") WITH CLUSTERING ORDER BY (opportunity_id DESC)\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* customer_id: Unique identifier for each customer\n",
        "* partner_id: AWS / Azure / GCP\n",
        "* opportunity_id: Unique identifier for each opportunity\n",
        "* opportunity: Dynamic collection of data field names and corresponindg values specific to the opportunity\n",
        "* llm_ouput: LLM output summarizing the 'next steps' , 'challenges' and 'open items'  \n",
        "* llm_ouput_embedding: Text embeddings corresponding to llm_output\n",
        "* sentiment: Positive, Neutral and Negative sentiment derived from 'next step' and 'cadence' data fields. This can be detrmined either by using a sentiment analysis library such as  Python Natural Language Toolkit (NLTK) or from LLM.\n"
      ],
      "metadata": {
        "id": "L2pRI7iZN45b"
      },
      "id": "L2pRI7iZN45b"
    },
    {
      "cell_type": "markdown",
      "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48",
      "metadata": {
        "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai cassandra-driver llama-index"
      ],
      "metadata": {
        "id": "uMoWlVK8ryqd"
      },
      "id": "uMoWlVK8ryqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.query import dict_factory\n",
        "from cassandra.query import SimpleStatement\n",
        "import openai\n",
        "from llama_index import ListIndex\n",
        "from llama_index.readers.schema.base import Document\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "ldfNIehRsB3W"
      },
      "id": "ldfNIehRsB3W",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d",
      "metadata": {
        "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d"
      },
      "source": [
        "# Keys & Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49",
      "metadata": {
        "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49"
      },
      "outputs": [],
      "source": [
        "# keys and tokens here\n",
        "openai_api_key = \"<open_api_key>\"\n",
        "openai.api_key = openai_api_key\n",
        "cass_user = '<user>'\n",
        "cass_pw = '<pwd>'\n",
        "scb_path = 'secure-connect-vector-search-demo.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96369f4-d311-44c2-8469-f960a2a8718a",
      "metadata": {
        "id": "a96369f4-d311-44c2-8469-f960a2a8718a"
      },
      "source": [
        "# Select a model to compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "553fece5-8154-4e18-9610-ff4999bfe171",
      "metadata": {
        "id": "553fece5-8154-4e18-9610-ff4999bfe171"
      },
      "outputs": [],
      "source": [
        "model_id = \"text-embedding-ada-002\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455",
      "metadata": {
        "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455"
      },
      "source": [
        "# Connect to the Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
        "outputId": "0e056ab0-e398-4363-f6c4-aa7faaa4f9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 78e5fc41-a92d-43ee-be98-1dc613a9792d-us-east1.db.astra.datastax.com:29042:2a7c8292-de7b-44eb-8409-c5a3c3fc70fc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 78e5fc41-a92d-43ee-be98-1dc613a9792d-us-east1.db.astra.datastax.com:29042:2a7c8292-de7b-44eb-8409-c5a3c3fc70fc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(138087894422944) 78e5fc41-a92d-43ee-be98-1dc613a9792d-us-east1.db.astra.datastax.com:29042:2a7c8292-de7b-44eb-8409-c5a3c3fc70fc> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 78e5fc41-a92d-43ee-be98-1dc613a9792d-us-east1.db.astra.datastax.com:29042:2a7c8292-de7b-44eb-8409-c5a3c3fc70fc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': scb_path\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(cass_user, cass_pw)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "session.set_keyspace('workspan')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0670b30f-927f-47da-b71d-0a99092c3f58",
      "metadata": {
        "id": "0670b30f-927f-47da-b71d-0a99092c3f58"
      },
      "source": [
        "# Drop / Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a941c487-1c6b-4f46-a0a3-305a95931d82",
      "metadata": {
        "id": "a941c487-1c6b-4f46-a0a3-305a95931d82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef50b369-7c82-44cf-846c-ca18b03b0725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7d971e44ae60>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "\n",
        "# # Create Table\n",
        "session.execute(f\"\"\"CREATE TABLE IF NOT EXISTS workspan.customer_opportunities (\n",
        "    customer_id text,\n",
        "    partner_id text,\n",
        "    opportunity_id text,\n",
        "    customer_name text static,\n",
        "    llm_output text,\n",
        "    opportunity map<text, text>,\n",
        "    llm_output_embedding vector<float, 1536>,\n",
        "    sentiment text,\n",
        "    PRIMARY KEY ((customer_id, partner_id), opportunity_id)\n",
        ") WITH CLUSTERING ORDER BY (opportunity_id DESC)\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session.execute(f\"\"\"CREATE CUSTOM INDEX ON workspan.customer_opportunities(opportunity) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLI4U_JqpAfI",
        "outputId": "07f5bce0-d5ba-4f92-b3d6-3bdd958075f6"
      },
      "id": "KLI4U_JqpAfI",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7d971e39d480>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session.execute(f\"\"\"CREATE CUSTOM INDEX ON workspan.customer_opportunities (llm_output_embedding) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeWFaC5Q5EjL",
        "outputId": "1f1bce93-db84-4ded-d6f9-386cc27bcf96"
      },
      "id": "oeWFaC5Q5EjL",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7d9717ed6bc0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session.execute(f\"\"\"CREATE CUSTOM INDEX ON workspan.customer_opportunities (sentiment) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAx4jimW6PaQ",
        "outputId": "8bf3ddf3-c2db-4cf7-9680-04a51998a270"
      },
      "id": "qAx4jimW6PaQ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7d971e55f940>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the following SAI with analyser from CQL\n",
        "\n",
        "\n",
        "```\n",
        "CREATE CUSTOM INDEX ON workspan.customer_opportunities(llm_output) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex' WITH OPTIONS = { 'index_analyzer': '{\n",
        "\"tokenizer\" : { \"name\" : \"ngram\", \"args\" : {\n",
        "\"minGramSize\":\"2\",\n",
        "\"maxGramSize\":\"3\" }\n",
        "},\n",
        "\"filters\" : [\n",
        "{\n",
        "\"name\" : \"lowercase\", \"args\": {}\n",
        "}\n",
        "],\n",
        "\"charFilters\" : []\n",
        "}' };\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BDLwp--lbTHa"
      },
      "id": "BDLwp--lbTHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the sentiment\n",
        "\n",
        "Sentiment can be calculated either by using a sentiment analysis library such as Python Natural Language Toolkit (NLTK) or from LLM."
      ],
      "metadata": {
        "id": "my8W1djmGEFZ"
      },
      "id": "my8W1djmGEFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def indentify_sentiment(next_step_and_cadence):\n",
        "    import nltk\n",
        "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "    nltk.download('vader_lexicon')\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "    sentiment_scores = sid.polarity_scores(next_step_and_cadence)\n",
        "    if sentiment_scores['compound'] >= 0.05:\n",
        "        sentiment = 'positive'\n",
        "    elif sentiment_scores['compound'] <= -0.05:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'neutral'\n",
        "\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "    return sentiment\n"
      ],
      "metadata": {
        "id": "8IubYIEwNMvB"
      },
      "id": "8IubYIEwNMvB",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate LLM ouput"
      ],
      "metadata": {
        "id": "SUVtAvlmGMTB"
      },
      "id": "SUVtAvlmGMTB"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_llm_information(next_step_and_cadence):\n",
        "    llm_input = f\"\"\"\n",
        "                Given the following information, please list out the challenges, next steps, and open items mentioned. Do not list 'next steps' if there is no follow-up meeting that needs to be scheduled or if it's mentioned that no further follow-up is required:\n",
        "\n",
        "                {next_step_and_cadence}\n",
        "\n",
        "                End of information.\n",
        "                \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the instructions provided to process the information.\"},\n",
        "            {\"role\": \"user\", \"content\": llm_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']"
      ],
      "metadata": {
        "id": "jLKLn4xLMNQV"
      },
      "id": "jLKLn4xLMNQV",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insert records with the calculated sentiment and LLM embeddings"
      ],
      "metadata": {
        "id": "5BqlxWG-zSZc"
      },
      "id": "5BqlxWG-zSZc"
    },
    {
      "cell_type": "code",
      "source": [
        "query = SimpleStatement(\n",
        "            f\"\"\"\n",
        "            INSERT INTO workspan.customer_opportunities\n",
        "            (customer_id, partner_id, opportunity_id, customer_name, llm_output,  opportunity , llm_output_embedding , sentiment )\n",
        "            VALUES (%s, %s, %s, %s, %s , %s , %s , %s )\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "# record #1\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Michael, confirmed deprioritize. From Anjaney, account executive interest to schedule meeting - Anjaney to schedule call with Nirav/Amy on R&D.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "Next Step:\n",
        "08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\n",
        "Next Step History:\n",
        "null;08/16/2023 : Review partner information updates and update opportunity details.;08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "sentiment = indentify_sentiment(next_step_and_cadence)\n",
        "llm_output = extract_llm_information(next_step_and_cadence)\n",
        "print(f\"{llm_output}/n\")\n",
        "embedding_llm_output = openai.Embedding.create(input= llm_output, model=model_id)['data'][0]['embedding']\n",
        "session.execute(query, ('CUS100' , 'AWS', 'WS-7202838a', 'Teradyne, Inc.', llm_output,  {'Customer State' : 'Ile-de-France', 'Customer Country' : 'France', 'Deal Size' : '30000', 'Description' : 'Pain Point: Persistent phishing attacks and email compromises leading to data leaks and compromised accounts. Description: The customer is struggling with the recurring threat of phishing attacks that infiltrate their systems, compromising sensitive data and risking the confidentiality of critical information.' }\n",
        "                        , embedding_llm_output , sentiment))\n",
        "\n",
        "# record #2\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Autumn, send recording of last call and our discussed inputs from demo 8/28. Ramesh will provide to Caroline by early next week (of 9/11).\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "REVIEW TECH & Economic Proposal\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "sentiment = indentify_sentiment(next_step_and_cadence)\n",
        "llm_output = extract_llm_information(next_step_and_cadence)\n",
        "print(f\"{llm_output}/n\")\n",
        "embedding_llm_output = openai.Embedding.create(input= llm_output, model=model_id)['data'][0]['embedding']\n",
        "session.execute(query, ('CUS100' , 'AWS', 'WS-8a038b8a', 'Teradyne, Inc.', llm_output,  {'Customer State' : 'Ile-de-France', 'Customer Country' : 'France', 'Deal Size' : '30000', 'Description' : 'Pain Point: Persistent phishing attacks and email compromises leading to data leaks and compromised accounts. Description: The customer is struggling with the recurring threat of phishing attacks that infiltrate their systems, compromising sensitive data and risking the confidentiality of critical information.' }\n",
        "                        , embedding_llm_output , sentiment))\n",
        "\n",
        "# record #3\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "Joint sync set for 9/7. Enablement session to follow + in person account mapping. Caroline / Michael to begin coordinating. EAI presence\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "sentiment = indentify_sentiment(next_step_and_cadence)\n",
        "llm_output = extract_llm_information(next_step_and_cadence)\n",
        "print(f\"{llm_output}/n\")\n",
        "embedding_llm_output = openai.Embedding.create(input= llm_output, model=model_id)['data'][0]['embedding']\n",
        "session.execute(query, ('CUS100' , 'AWS', 'WS-8a3b0348', 'Teradyne, Inc.', llm_output,  {'Customer State' : 'Ile-de-France', 'Customer Country' : 'France', 'Deal Size' : '30000', 'Description' : 'Pain Point: Persistent phishing attacks and email compromises leading to data leaks and compromised accounts. Description: The customer is struggling with the recurring threat of phishing attacks that infiltrate their systems, compromising sensitive data and risking the confidentiality of critical information.' }\n",
        "                        , embedding_llm_output , sentiment))\n",
        "\n",
        "# record #4\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Caroline, user community engaged to respond to questions. @Dataiku - How can we get initial data from user community/pull together PoV for client? Action (Asan/Ken (sp?)): In-person outreach to Deloitte users and follow-up to 5 responses received.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "null;06/20/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support;07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "sentiment = indentify_sentiment(next_step_and_cadence)\n",
        "llm_output = extract_llm_information(next_step_and_cadence)\n",
        "print(f\"{llm_output}/n\")\n",
        "embedding_llm_output = openai.Embedding.create(input= llm_output, model=model_id)['data'][0]['embedding']\n",
        "session.execute(query, ('CUS100' , 'AWS', 'WS-8a7128a3', 'Teradyne, Inc.', llm_output,  {'Customer State' : 'Ile-de-France', 'Customer Country' : 'France', 'Deal Size' : '30000', 'Description' : 'Pain Point: Persistent phishing attacks and email compromises leading to data leaks and compromised accounts. Description: The customer is struggling with the recurring threat of phishing attacks that infiltrate their systems, compromising sensitive data and risking the confidentiality of critical information.' }\n",
        "                        , embedding_llm_output , sentiment))\n",
        "\n",
        "# record #4\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Propsal did not go thru. No budget Left. Negative.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "No further follow up required.\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "sentiment = indentify_sentiment(next_step_and_cadence)\n",
        "llm_output = extract_llm_information(next_step_and_cadence)\n",
        "print(f\"{llm_output}/n\")\n",
        "embedding_llm_output = openai.Embedding.create(input= llm_output, model=model_id)['data'][0]['embedding']\n",
        "session.execute(query, ('CUS100' , 'AWS', 'WS-8a7128a4', 'Teradyne, Inc.', llm_output,  {'Customer State' : 'Ile-de-France', 'Customer Country' : 'France', 'Deal Size' : '30000', 'Description' : 'Pain Point: Persistent phishing attacks and email compromises leading to data leaks and compromised accounts. Description: The customer is struggling with the recurring threat of phishing attacks that infiltrate their systems, compromising sensitive data and risking the confidentiality of critical information.' }\n",
        "                        , embedding_llm_output , sentiment))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IedeKXPDv2Rv",
        "outputId": "67b5093a-e279-4add-bb34-0230f4d68081"
      },
      "id": "IedeKXPDv2Rv",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n",
            "Challenges:\n",
            "- The main challenge is the deprioritization of the project by Michael.\n",
            "\n",
            "Next Steps:\n",
            "- Anjaney needs to schedule a call with Nirav and Amy on R&D.\n",
            "- Review partner information updates and update opportunity details on 08/16/2023.\n",
            "- Connect with the partner on 08/17 to offer co-sell support.\n",
            "\n",
            "Open Items:\n",
            "- There are no specific open items mentioned in the provided information./n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: neutral\n",
            "Challenges:\n",
            "- No challenges mentioned in the given information.\n",
            "\n",
            "Next Steps:\n",
            "- Autumn to send recording of last call and discussed inputs from demo on 8/28 to Caroline.\n",
            "- Ramesh to provide the recording and discussed inputs to Caroline by early next week (of 9/11).\n",
            "\n",
            "Open Items:\n",
            "- No open items mentioned in the given information./n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n",
            "Challenges:\n",
            "1. The coordination of the joint sync and enablement session needs to be managed by Caroline and Michael.\n",
            "2. The presence of EAI needs to be ensured for the joint sync.\n",
            "\n",
            "Next Steps:\n",
            "1. Schedule a joint sync for 9/7 and coordinate the enablement session with Caroline and Michael.\n",
            "2. Contact Federico Gandolfo at federico.hernan.gandolfo@abc.com or +54.911.3204.4871 to discuss deal support.\n",
            "\n",
            "Open Items:\n",
            "None mentioned in the given information./n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n",
            "Challenges mentioned:\n",
            "- Engaging the user community to respond to questions\n",
            "- Getting initial data from the user community and pulling together a Point of View (PoV) for the client\n",
            "- In-person outreach to Deloitte users and follow-up to 5 responses received\n",
            "\n",
            "Next Steps:\n",
            "- In-person outreach to Deloitte users and follow-up on 5 responses received\n",
            "\n",
            "Open Items:\n",
            "- It is unclear if any further follow-up is required or if a follow-up meeting needs to be scheduled./n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: negative\n",
            "Based on the given information, the challenges mentioned are:\n",
            "1. The proposal did not go through.\n",
            "2. There is no budget left.\n",
            "3. The situation is negative.\n",
            "\n",
            "The next steps are not mentioned in the provided information.\n",
            "\n",
            "The open items mentioned are:\n",
            "1. No further follow-up is required./n\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7d971e1b0d60>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Opportunity Specific Queries"
      ],
      "metadata": {
        "id": "eFUGSeuhGZ2M"
      },
      "id": "eFUGSeuhGZ2M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the customer sentiment on this opportunity?"
      ],
      "metadata": {
        "id": "Ow36bzT-2r1s"
      },
      "id": "Ow36bzT-2r1s"
    },
    {
      "cell_type": "code",
      "source": [
        "cqlSelect = f'''SELECT * FROM workspan.customer_opportunities WHERE customer_id = 'CUS100' and partner_id = 'AWS' and opportunity_id = 'WS-7202838a'  ;'''\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    customer_id:      {row.customer_id}')\n",
        "    print(f'    partner_id:      {row.partner_id}')\n",
        "    print(f'    opportunity_id:      {row.opportunity_id}')\n",
        "    print(f'    customer_name:      {row.customer_name}')\n",
        "    print(f'    sentiment:      {row.sentiment}')\n",
        "\n",
        "print('\\n...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POI0ET0X2mai",
        "outputId": "292fd535-ce71-445b-fd59-16e3b239eeab"
      },
      "id": "POI0ET0X2mai",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 0:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-7202838a\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the next steps for this opportunity? Result can be further parsed to display only the next steps. Same query returns open items and challenges as well.  "
      ],
      "metadata": {
        "id": "CDLLgfk0338_"
      },
      "id": "CDLLgfk0338_"
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding = openai.Embedding.create(input= vectorsearchon, model=model_id)['data'][0]['embedding']\n",
        "\n",
        "cqlSelect = f'''SELECT * FROM workspan.customer_opportunities WHERE customer_id = 'CUS100' and partner_id = 'AWS' and opportunity_id = 'WS-7202838a';  '''\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    customer_id:      {row.customer_id}')\n",
        "    print(f'    partner_id:      {row.partner_id}')\n",
        "    print(f'    opportunity_id:      {row.opportunity_id}')\n",
        "    print(f'    customer_name:      {row.customer_name}')\n",
        "    print(f'    llm_output:    \\n  {row.llm_output}')\n",
        "\n",
        "print('\\n...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM03gRZT4A7v",
        "outputId": "2b77bafa-8404-4698-8136-8b4462e307f9"
      },
      "id": "pM03gRZT4A7v",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 0:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-7202838a\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    llm_output:    \n",
            "  Challenges:\n",
            "- The main challenge is the deprioritization of the project by Michael.\n",
            "\n",
            "Next Steps:\n",
            "- Anjaney needs to schedule a call with Nirav and Amy on R&D.\n",
            "- Review partner information updates and update opportunity details on 08/16/2023.\n",
            "- Connect with the partner on 08/17 to offer co-sell support.\n",
            "\n",
            "Open Items:\n",
            "- There are no specific open items mentioned in the provided information.\n",
            "\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Specific Queries (across multiple opportunities)"
      ],
      "metadata": {
        "id": "SDbPnN2uJsq0"
      },
      "id": "SDbPnN2uJsq0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the wins"
      ],
      "metadata": {
        "id": "s_jSZKP7zUss"
      },
      "id": "s_jSZKP7zUss"
    },
    {
      "cell_type": "code",
      "source": [
        "cqlSelect = f'''SELECT * FROM workspan.customer_opportunities WHERE customer_id = 'CUS100' and partner_id = 'AWS' and sentiment = 'positive'  ;'''\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    customer_id:      {row.customer_id}')\n",
        "    print(f'    partner_id:      {row.partner_id}')\n",
        "    print(f'    opportunity_id:      {row.opportunity_id}')\n",
        "    print(f'    customer_name:      {row.customer_name}')\n",
        "    print(f'    sentiment:      {row.sentiment}')\n",
        "\n",
        "print('\\n...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4cgsK4K5Z_l",
        "outputId": "cc63da78-f5a5-4f1b-a107-95cbd2e7ca37"
      },
      "id": "A4cgsK4K5Z_l",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 0:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-8a7128a3\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "\n",
            "Row 1:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-8a3b0348\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "\n",
            "Row 2:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-7202838a\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify opportunities with next step to schedule a meeting"
      ],
      "metadata": {
        "id": "RvHXXjLL8vfh"
      },
      "id": "RvHXXjLL8vfh"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorsearchon = 'next action to set up a meeting'\n",
        "embedding = openai.Embedding.create(input= vectorsearchon, model=model_id)['data'][0]['embedding']\n",
        "\n",
        "cqlSelect = f'''SELECT * FROM workspan.customer_opportunities WHERE customer_id = 'CUS100' and partner_id = 'AWS' and llm_output : 'schedule' ORDER BY llm_output_embedding ANN OF {embedding} LIMIT 10;  '''\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    customer_id:      {row.customer_id}')\n",
        "    print(f'    partner_id:      {row.partner_id}')\n",
        "    print(f'    opportunity_id:      {row.opportunity_id}')\n",
        "    print(f'    customer_name:      {row.customer_name}')\n",
        "    print(f'    sentiment:      {row.sentiment}')\n",
        "    print(f'    llm_output:    \\n  {row.llm_output}')\n",
        "\n",
        "print('\\n...')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8HJPTwC8wH5",
        "outputId": "5ce94699-cc57-49d5-fb14-f4ae30214620"
      },
      "id": "a8HJPTwC8wH5",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 0:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-8a7128a3\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "    llm_output:    \n",
            "  Challenges mentioned:\n",
            "- Engaging the user community to respond to questions\n",
            "- Getting initial data from the user community and pulling together a Point of View (PoV) for the client\n",
            "- In-person outreach to Deloitte users and follow-up to 5 responses received\n",
            "\n",
            "Next Steps:\n",
            "- In-person outreach to Deloitte users and follow-up on 5 responses received\n",
            "\n",
            "Open Items:\n",
            "- It is unclear if any further follow-up is required or if a follow-up meeting needs to be scheduled.\n",
            "\n",
            "Row 1:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-7202838a\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "    llm_output:    \n",
            "  Challenges:\n",
            "- The main challenge is the deprioritization of the project by Michael.\n",
            "\n",
            "Next Steps:\n",
            "- Anjaney needs to schedule a call with Nirav and Amy on R&D.\n",
            "- Review partner information updates and update opportunity details on 08/16/2023.\n",
            "- Connect with the partner on 08/17 to offer co-sell support.\n",
            "\n",
            "Open Items:\n",
            "- There are no specific open items mentioned in the provided information.\n",
            "\n",
            "Row 2:\n",
            "    customer_id:      CUS100\n",
            "    partner_id:      AWS\n",
            "    opportunity_id:      WS-8a3b0348\n",
            "    customer_name:      Teradyne, Inc.\n",
            "    sentiment:      positive\n",
            "    llm_output:    \n",
            "  Challenges:\n",
            "1. The coordination of the joint sync and enablement session needs to be managed by Caroline and Michael.\n",
            "2. The presence of EAI needs to be ensured for the joint sync.\n",
            "\n",
            "Next Steps:\n",
            "1. Schedule a joint sync for 9/7 and coordinate the enablement session with Caroline and Michael.\n",
            "2. Contact Federico Gandolfo at federico.hernan.gandolfo@abc.com or +54.911.3204.4871 to discuss deal support.\n",
            "\n",
            "Open Items:\n",
            "None mentioned in the given information.\n",
            "\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to know more about the customer and the challenges so that it is possible to plan accordingly (Implement query using agent framework such as LangChain, LlamaIndex)"
      ],
      "metadata": {
        "id": "VUCjFRriuhYs"
      },
      "id": "VUCjFRriuhYs"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorsearchon = 'Challenges'\n",
        "embedding = openai.Embedding.create(input= vectorsearchon, model=model_id)['data'][0]['embedding']\n",
        "\n",
        "cqlSelect = f'''SELECT llm_output FROM workspan.customer_opportunities WHERE customer_id = 'CUS100' and partner_id = 'AWS' ORDER BY llm_output_embedding ANN OF {embedding} LIMIT 10;  '''\n",
        "rows = session.execute(cqlSelect)\n",
        "print(rows)\n",
        "documents = []\n",
        "for item in rows:\n",
        "    documents.append(Document(text=str(item)))\n",
        "    print(str(item))\n",
        "\n",
        "index = ListIndex.from_documents(documents)\n",
        "\n",
        "# set Logging to DEBUG for more detailed outputs\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What are the Challenges?\")\n",
        "\n",
        "# visualize in console or web\n",
        "print(response)\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dxdohOBTZqCI",
        "outputId": "1220da1e-40ef-4496-8d41-1e30e790a921"
      },
      "id": "dxdohOBTZqCI",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<cassandra.cluster.ResultSet object at 0x7d9715359b40>\n",
            "Row(llm_output='Challenges mentioned:\\n- Engaging the user community to respond to questions\\n- Getting initial data from the user community and pulling together a Point of View (PoV) for the client\\n- In-person outreach to Deloitte users and follow-up to 5 responses received\\n\\nNext Steps:\\n- In-person outreach to Deloitte users and follow-up on 5 responses received\\n\\nOpen Items:\\n- It is unclear if any further follow-up is required or if a follow-up meeting needs to be scheduled.')\n",
            "Row(llm_output='Challenges:\\n- No challenges mentioned in the given information.\\n\\nNext Steps:\\n- Autumn to send recording of last call and discussed inputs from demo on 8/28 to Caroline.\\n- Ramesh to provide the recording and discussed inputs to Caroline by early next week (of 9/11).\\n\\nOpen Items:\\n- No open items mentioned in the given information.')\n",
            "Row(llm_output='Based on the given information, the challenges mentioned are:\\n1. The proposal did not go through.\\n2. There is no budget left.\\n3. The situation is negative.\\n\\nThe next steps are not mentioned in the provided information.\\n\\nThe open items mentioned are:\\n1. No further follow-up is required.')\n",
            "Row(llm_output='Challenges:\\n- The main challenge is the deprioritization of the project by Michael.\\n\\nNext Steps:\\n- Anjaney needs to schedule a call with Nirav and Amy on R&D.\\n- Review partner information updates and update opportunity details on 08/16/2023.\\n- Connect with the partner on 08/17 to offer co-sell support.\\n\\nOpen Items:\\n- There are no specific open items mentioned in the provided information.')\n",
            "Row(llm_output='Challenges:\\n1. The coordination of the joint sync and enablement session needs to be managed by Caroline and Michael.\\n2. The presence of EAI needs to be ensured for the joint sync.\\n\\nNext Steps:\\n1. Schedule a joint sync for 9/7 and coordinate the enablement session with Caroline and Michael.\\n2. Contact Federico Gandolfo at federico.hernan.gandolfo@abc.com or +54.911.3204.4871 to discuss deal support.\\n\\nOpen Items:\\nNone mentioned in the given information.')\n",
            "The challenges mentioned in the given context information are as follows:\n",
            "1. Engaging the user community to respond to questions\n",
            "2. Getting initial data from the user community and pulling together a Point of View (PoV) for the client\n",
            "3. In-person outreach to Deloitte users and follow-up to 5 responses received\n",
            "4. The main challenge is the deprioritization of the project by Michael\n",
            "5. The coordination of the joint sync and enablement session needs to be managed by Caroline and Michael\n",
            "6. The presence of EAI needs to be ensured for the joint sync.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>The challenges mentioned in the given context information are as follows:\n1. Engaging the user community to respond to questions\n2. Getting initial data from the user community and pulling together a Point of View (PoV) for the client\n3. In-person outreach to Deloitte users and follow-up to 5 responses received\n4. The main challenge is the deprioritization of the project by Michael\n5. The coordination of the joint sync and enablement session needs to be managed by Caroline and Michael\n6. The presence of EAI needs to be ensured for the joint sync.</b>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}